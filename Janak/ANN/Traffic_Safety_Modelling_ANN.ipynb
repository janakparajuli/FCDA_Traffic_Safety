{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network for Binary Classification of Accident Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this model, we will build an artificial neural network (ANN) for binary classification of accident data. This model can be used with any accident data changing just the columns accordingly. Here we implement this model using Unfallatlas data of Germany."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Firstly, we begin with some adjustment with the data and understanding the relation between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import the dataset. We will use the accident data from Unfallatlas of Germany.\n",
    "dataset = pd.read_csv('Unfallorte_Combined.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SN</th>\n",
       "      <th>District</th>\n",
       "      <th>Imperial_Circle</th>\n",
       "      <th>Community</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Road</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>...</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Goods Vehicle</th>\n",
       "      <th>Others</th>\n",
       "      <th>Total</th>\n",
       "      <th>Collision Type</th>\n",
       "      <th>Accident Type</th>\n",
       "      <th>Light Condition</th>\n",
       "      <th>Road Condition</th>\n",
       "      <th>Accident_Severity</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>710</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>610</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>317</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21465</th>\n",
       "      <td>21466</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21466</th>\n",
       "      <td>21467</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21467</th>\n",
       "      <td>21468</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>21469</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21469</th>\n",
       "      <td>21470</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>517</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21470 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SN  District  Imperial_Circle  Community  Year  Month  Weekday  \\\n",
       "0          1         7                9        710  2016      2        4   \n",
       "1          2         1               19        140  2016      4        7   \n",
       "2          3         6                9        610  2016      1        2   \n",
       "3          4         1                1        102  2016      3        7   \n",
       "4          5         3                5        317  2016      2        1   \n",
       "...      ...       ...              ...        ...   ...    ...      ...   \n",
       "21465  21466         3                2        312  2018     12        6   \n",
       "21466  21467         3                1        310  2018     12        6   \n",
       "21467  21468         2                1        201  2018     12        6   \n",
       "21468  21469         1                3        105  2018     12        6   \n",
       "21469  21470         5                9        517  2018     12        5   \n",
       "\n",
       "       Hour  Road  Cycle  ...  Motorcycle  Goods Vehicle  Others  Total  \\\n",
       "0        16     0      0  ...           1              0       0      2   \n",
       "1        11     0      0  ...           0              0       1      2   \n",
       "2        13     0      0  ...           0              0       0      2   \n",
       "3        16     0      0  ...           1              0       1      3   \n",
       "4        18     0      0  ...           0              0       0      1   \n",
       "...     ...   ...    ...  ...         ...            ...     ...    ...   \n",
       "21465    17     0      0  ...           0              0       0      2   \n",
       "21466     8     0      1  ...           0              0       0      2   \n",
       "21467    14     0      0  ...           0              0       0      1   \n",
       "21468    10     0      1  ...           0              0       0      2   \n",
       "21469    22     0      0  ...           0              0       0      1   \n",
       "\n",
       "       Collision Type  Accident Type  Light Condition  Road Condition  \\\n",
       "0                   2              2                0               3   \n",
       "1                   2              6                0               3   \n",
       "2                   6              4                0               3   \n",
       "3                   2              6                0               3   \n",
       "4                   9              1                2               3   \n",
       "...               ...            ...              ...             ...   \n",
       "21465               6              7                3               1   \n",
       "21466               3              2                3               1   \n",
       "21467               2              7                3               1   \n",
       "21468               1              5                3               1   \n",
       "21469               1              5                3               1   \n",
       "\n",
       "       Accident_Severity  Severity  \n",
       "0                      3         0  \n",
       "1                      3         0  \n",
       "2                      2         1  \n",
       "3                      2         1  \n",
       "4                      3         0  \n",
       "...                  ...       ...  \n",
       "21465                  3         0  \n",
       "21466                  3         0  \n",
       "21467                  3         0  \n",
       "21468                  3         0  \n",
       "21469                  3         0  \n",
       "\n",
       "[21470 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we will use the severity column of data. Accidents with casualties, serious injuries and heavy property damage are considered as severe(1) and those with no casualty, minor injury, less property damage are considered as minor(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Tool for Correlation between variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before going for modeling, lets study the relationship between the variables involved through correlation diagram. We will use District(1),Month(5),Weekday(6),Light Condition(15) and Road Condition(18) and Severity variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Imperial_Circle</th>\n",
       "      <th>Community</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Light Condition</th>\n",
       "      <th>Road Condition</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>710</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>610</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>317</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21465</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21466</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21467</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21469</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>517</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21470 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       District  Imperial_Circle  Community  Month  Weekday  Hour  \\\n",
       "0             7                9        710      2        4    16   \n",
       "1             1               19        140      4        7    11   \n",
       "2             6                9        610      1        2    13   \n",
       "3             1                1        102      3        7    16   \n",
       "4             3                5        317      2        1    18   \n",
       "...         ...              ...        ...    ...      ...   ...   \n",
       "21465         3                2        312     12        6    17   \n",
       "21466         3                1        310     12        6     8   \n",
       "21467         2                1        201     12        6    14   \n",
       "21468         1                3        105     12        6    10   \n",
       "21469         5                9        517     12        5    22   \n",
       "\n",
       "       Light Condition  Road Condition  Severity  Total  \n",
       "0                    0               3         0      2  \n",
       "1                    0               3         0      2  \n",
       "2                    0               3         1      2  \n",
       "3                    0               3         1      3  \n",
       "4                    2               3         0      1  \n",
       "...                ...             ...       ...    ...  \n",
       "21465                3               1         0      2  \n",
       "21466                3               1         0      2  \n",
       "21467                3               1         0      1  \n",
       "21468                3               1         0      2  \n",
       "21469                3               1         0      1  \n",
       "\n",
       "[21470 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data = dataset[['District','Imperial_Circle','Community', 'Month', 'Weekday','Hour', 'Light Condition', 'Road Condition', 'Severity', 'Total']]\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First lets import the library\n",
    "import seaborn as sns\n",
    "corr = corr_data.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can observe moderate correlation between severity and other variables. Total accident has slightly negative relations with light condition, month and weekday. It has positive relation with road condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Tools for Preprocessing of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical values into integers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We need to select only those independent variables that influence dependent variables. We should check the types of these variables. String variables should be converted to floating values. In our data there are no string values. Had there been string values, we would have converted the column using: \n",
    "\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [<Index of column>])], remainder='passthrough')\n",
    "X[:, <Index of column>:] = np.array(ct.fit_transform(X[:, <Index of column>:]), dtype=np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['District', 'Imperial_Circle', 'Community', 'Month', 'Weekday', 'Hour',\n",
       "       'Light Condition', 'Road Condition', 'Severity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take only those variables which can have effect to accident, \n",
    "#District(1),Imperial_Circle(2), Community(3), Month(5),Weekday(6),Hour(7), Light Condition(18) and Road Condition(19) and Severity\n",
    "check = dataset.iloc[:, [1,2,3,5,6,7,18,19,-1]].columns\n",
    "X = dataset.iloc[:, [1,2,3,5,6,7,18,19]].values \n",
    "y = dataset.iloc[:, [-1]].values\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "#Check the types of the variables\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Both are integers, so we are fine to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill out the missing values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X).any())\n",
    "print(np.isnan(y).any())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are no null values in this data. Had there been any, the following code can be used to fill it with the column mean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fill out the missing values with their mean\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, <range of columns to check for>] = imputer.transform(X[:, <range of columns to check for>])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Tools for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is necessary to split the data into two sections before proceeding for modeling. Also there is a question that whether data standardizations should be done before or after splitting. It should be kept in mind that if scaling is done before splitting then there will be leakage of information between training dataset and testing dataset which makes the model testing meaningless. Hence, there should be no doubt that data scaling should be done only after splitting the dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is normal practice to split the dataset in the ration of 80:20 between training set and testing set. random_state varible will split the data with same random effect, so if this variable is not set then there is no point of splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now is the time for standardizing the dataset. However, in data science practiotioners are often in confusion whether to standardize or normalize the data. It should be noted that data standardization works for all sorts of data and gives the range of values generally from -3 to +3 while data normalization is fine for only those data with normal distribution and it gives range betwen 0 and 1. So, as a rule of thumb we will do data standardization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `StandardScaler` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the train set\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)\n",
    "#It should be kept in mind never to use fit() function for testing set. \n",
    "#If it is used, fit() method will create a new scaler for testing set also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16102, 8)\n",
      "(5368, 8)\n",
      "(16102, 1)\n",
      "(5368, 1)\n"
     ]
    }
   ],
   "source": [
    "#See the shape of training and testing set\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To build the model, we initilize it with Sequential constructor at first. The parameters for modeling should be chosen based on the input data and output data. Number of hidden layers are chosen either:\n",
    "    a. Between the number of input and output data\n",
    "    b. Hit and trial basis for which the model performs the best."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is the explanation of our chosen parameters:\n",
    "input_dim = 8: There are eight training variables in our data\n",
    "'activation' of hidden layers  = 'relu': To remove the linearity between variables.\n",
    "kernel_initializer = 'uniform' : To uniformly initilize the model\n",
    "units = 4 : Rule of thumb is (input variables + output variables)/2. Not mandatory though but in this case we followed this                 rule.\n",
    "'activation' of output layer = 'sigmoid': Our output is binary so we chose 'sigmoid'. Had it been multi-class, we would have                                             chose 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "classifier = Sequential()\n",
    "\n",
    "# Add an input+hidden layer \n",
    "classifier.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8))\n",
    "\n",
    "# Add first hidden layer \n",
    "classifier.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# Add second hidden layer \n",
    "classifier.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# Add third hidden layer \n",
    "#classifier.add(Dense(4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# Add an output layer \n",
    "classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Know the properties of model we are building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.02139466, -0.02977877, -0.01343446, -0.02575888, -0.01994397],\n",
       "        [ 0.0110788 , -0.03580685, -0.01877223,  0.00226227,  0.02123595],\n",
       "        [ 0.04380604, -0.03686342,  0.017921  ,  0.01677981, -0.04025381],\n",
       "        [ 0.00141595, -0.03293262,  0.00058319, -0.04833018,  0.02094451],\n",
       "        [ 0.0392195 ,  0.0294704 ,  0.03381319, -0.02841702,  0.02640035],\n",
       "        [ 0.01476157,  0.01112231, -0.02313279,  0.01453217, -0.03058726],\n",
       "        [ 0.04722903,  0.03029453,  0.03824108, -0.0037159 , -0.04580723],\n",
       "        [ 0.04152537, -0.00592498,  0.04100415, -0.00762299, -0.04820198]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.02900451,  0.00642338,  0.04556772, -0.03266777, -0.03020843],\n",
       "        [-0.01440517,  0.04146104,  0.03392644,  0.00725701,  0.00505032],\n",
       "        [-0.02506327, -0.0146725 , -0.04012086, -0.03320669, -0.03076803],\n",
       "        [ 0.02190397, -0.01411793,  0.03687609, -0.01788257, -0.01867478],\n",
       "        [-0.01657257, -0.0440986 ,  0.04009474, -0.02598031,  0.02759231]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.01160704,  0.03968098,  0.02122367,  0.01324633, -0.04198694],\n",
       "        [-0.0142923 , -0.02755733,  0.04578941, -0.00173212,  0.00740724],\n",
       "        [-0.0319141 ,  0.04944458, -0.01000614,  0.02527591, -0.00182126],\n",
       "        [ 0.0222005 , -0.04355574, -0.01559849,  0.02884733,  0.00691639],\n",
       "        [-0.03866187,  0.04065032,  0.02402126, -0.02974651, -0.02033918]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[0.01926031],\n",
       "        [0.0198606 ],\n",
       "        [0.02577758],\n",
       "        [0.01448714],\n",
       "        [0.03192414]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "classifier.output_shape\n",
    "\n",
    "# Model summary\n",
    "classifier.summary()\n",
    "\n",
    "# Model configuration\n",
    "#classifier.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "classifier.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is an explanation of parameters chosen for compiling and fitting:\n",
    "loss = 'binary_crossentropy':The model is binary\n",
    "optimizer = 'adam': Stochastic gradient descent(SGD) is suitable approach to find the global minimum between over-fitting and under-fitting. 'adam' is a type of SGD. You can use 'rmsprop' also.\n",
    "metrics = 'accuracy': We want to quantify the performance and accuracy of model.\n",
    "epochs = 50: It is set on hit and trail basis. Can be changed according to the model performance.\n",
    "batch_size = 10: It is set on hit and trail basis. Can be changed according to the model performance.\n",
    "verbose = 1: To see the model progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "16102/16102 [==============================] - 2s 118us/step - loss: 0.5017 - accuracy: 0.8931\n",
      "Epoch 2/75\n",
      "16102/16102 [==============================] - 2s 101us/step - loss: 0.3609 - accuracy: 0.8934\n",
      "Epoch 3/75\n",
      "16102/16102 [==============================] - 2s 97us/step - loss: 0.3414 - accuracy: 0.8934\n",
      "Epoch 4/75\n",
      "16102/16102 [==============================] - 2s 98us/step - loss: 0.3396 - accuracy: 0.8934\n",
      "Epoch 5/75\n",
      "16102/16102 [==============================] - 2s 98us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 6/75\n",
      "16102/16102 [==============================] - 2s 97us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 7/75\n",
      "16102/16102 [==============================] - 2s 97us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 8/75\n",
      "16102/16102 [==============================] - 2s 107us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 9/75\n",
      "16102/16102 [==============================] - 2s 113us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 10/75\n",
      "16102/16102 [==============================] - 2s 121us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 11/75\n",
      "16102/16102 [==============================] - 2s 121us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 12/75\n",
      "16102/16102 [==============================] - 2s 120us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 13/75\n",
      "16102/16102 [==============================] - 2s 108us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 14/75\n",
      "16102/16102 [==============================] - 2s 109us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 15/75\n",
      "16102/16102 [==============================] - 2s 107us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 16/75\n",
      "16102/16102 [==============================] - 2s 107us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 17/75\n",
      "16102/16102 [==============================] - 2s 106us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 18/75\n",
      "16102/16102 [==============================] - 2s 111us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 19/75\n",
      "16102/16102 [==============================] - 2s 112us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 20/75\n",
      "16102/16102 [==============================] - 2s 109us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 21/75\n",
      "16102/16102 [==============================] - 2s 107us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 22/75\n",
      "16102/16102 [==============================] - 2s 105us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 23/75\n",
      "16102/16102 [==============================] - 2s 105us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 24/75\n",
      "16102/16102 [==============================] - 2s 107us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 25/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 26/75\n",
      "16102/16102 [==============================] - 2s 122us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 27/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 28/75\n",
      "16102/16102 [==============================] - 2s 110us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 29/75\n",
      "16102/16102 [==============================] - 2s 113us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 30/75\n",
      "16102/16102 [==============================] - 2s 110us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 31/75\n",
      "16102/16102 [==============================] - 2s 106us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 32/75\n",
      "16102/16102 [==============================] - 2s 112us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 33/75\n",
      "16102/16102 [==============================] - 2s 113us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 34/75\n",
      "16102/16102 [==============================] - 2s 110us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 35/75\n",
      "16102/16102 [==============================] - 2s 108us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 36/75\n",
      "16102/16102 [==============================] - 2s 110us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 37/75\n",
      "16102/16102 [==============================] - 2s 109us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 38/75\n",
      "16102/16102 [==============================] - 2s 111us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 39/75\n",
      "16102/16102 [==============================] - 2s 109us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 40/75\n",
      "16102/16102 [==============================] - 2s 112us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 41/75\n",
      "16102/16102 [==============================] - 2s 111us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 42/75\n",
      "16102/16102 [==============================] - 2s 145us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 43/75\n",
      "16102/16102 [==============================] - 2s 109us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 44/75\n",
      "16102/16102 [==============================] - 2s 109us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 45/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 46/75\n",
      "16102/16102 [==============================] - 2s 121us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 47/75\n",
      "16102/16102 [==============================] - 2s 132us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 48/75\n",
      "16102/16102 [==============================] - 2s 145us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 49/75\n",
      "16102/16102 [==============================] - 2s 130us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 50/75\n",
      "16102/16102 [==============================] - 2s 119us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 51/75\n",
      "16102/16102 [==============================] - 2s 148us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 52/75\n",
      "16102/16102 [==============================] - 2s 141us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 53/75\n",
      "16102/16102 [==============================] - 2s 138us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 54/75\n",
      "16102/16102 [==============================] - 2s 137us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 55/75\n",
      "16102/16102 [==============================] - 2s 118us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 56/75\n",
      "16102/16102 [==============================] - 2s 128us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 57/75\n",
      "16102/16102 [==============================] - 2s 116us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 58/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 59/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 60/75\n",
      "16102/16102 [==============================] - 2s 125us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 61/75\n",
      "16102/16102 [==============================] - 2s 123us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 62/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 63/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 64/75\n",
      "16102/16102 [==============================] - 2s 136us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 65/75\n",
      "16102/16102 [==============================] - 2s 128us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 66/75\n",
      "16102/16102 [==============================] - 2s 127us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 67/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 68/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3394 - accuracy: 0.8934\n",
      "Epoch 69/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 70/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 71/75\n",
      "16102/16102 [==============================] - 2s 116us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 72/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 73/75\n",
      "16102/16102 [==============================] - 2s 113us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 74/75\n",
      "16102/16102 [==============================] - 2s 115us/step - loss: 0.3395 - accuracy: 0.8934\n",
      "Epoch 75/75\n",
      "16102/16102 [==============================] - 2s 114us/step - loss: 0.3395 - accuracy: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2297ba1a488>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "classifier.fit(X_train, y_train, epochs=75, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now, lets predict with the test set prepared previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To evaluate, we will compute the following:\n",
    "The confusion matrix: is a breakdown of predictions into a table showing correct predictions and the types of incorrect                               predictions made. Ideally, you will only see numbers in the diagonal, which means that all your                                 predictions were correct!\n",
    "Precision: is a measure of a classifier’s exactness. The higher the precision, the more accurate the classifier.\n",
    "Recall: is a measure of a classifier’s completeness. The higher the recall, the more cases the classifier covers.\n",
    "The F1 Score or F-score: is a weighted average of precision and recall.\n",
    "The Kappa or Cohen’s kappa: is the classification accuracy normalized by the imbalance of the classes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5368/5368 [==============================] - 0s 19us/step\n",
      "The loss of the model is: 0.34 and the accuracy is: 89.53%\n"
     ]
    }
   ],
   "source": [
    "#Lets begin with the scores of the model\n",
    "loss, accuracy = classifier.evaluate(X_test, y_test,verbose=1)\n",
    "print(f'The loss of the model is: {round(loss,2)} and the accuracy is: {round(accuracy,4)*100}%')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Alternately we can also compute the accuracy from confusion matrix also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is: 89.53%\n"
     ]
    }
   ],
   "source": [
    "# Import the modules from `sklearn.metrics`\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Confusion matrix\n",
    "y_preds = y_pred>0.2\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "overall_accu = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "print(f'The overall accuracy is: {round(overall_accu,4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision \n",
    "precision_score(y_test, y_preds, zero_division = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "recall_score(y_test, y_preds, zero_division = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "f1_score(y_test,y_preds, zero_division = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cohen's kappa\n",
    "cohen_kappa_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now, lets consider few scenario in order to predict the probability of accidents based on some criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Case Studies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is tend to death at the said condition [[False]]\n"
     ]
    }
   ],
   "source": [
    "#Analytical Questions\n",
    "#District(1),Imperial_Circle(2), Community(3), Month(5),Weekday(6),Hour(7), Light Condition(18) and Road Condition(19) and Severity\n",
    "#Q1. Which sort of accident occur in imperial circle 3, community 5 of district 4 at 11 am on saturday of July at morning when the road \n",
    "#is dry?\n",
    "\"\"\"Solution:\n",
    "    District - 4 ---[1,0,0,0,0,1,0]\n",
    "    Imperial Circle - 3\n",
    "    Community - 5\n",
    "    Month - July - 7 --- [1,0,0,0,0,0,0,0,0,1,0,0]\n",
    "    Weekday - Weekend - [0,0,0,0,0,0,0,0]\n",
    "    Hour - 11\n",
    "    Light Condition - Morning - 1 - [1]\n",
    "    Road Condition - Dry - 0 - [0]\n",
    "    \"\"\"\n",
    "test_data = [4,3,5,7,7,11,1,0]\n",
    "test_pred = classifier.predict(scaler.transform([test_data]))\n",
    "#new_data = [1.0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "#new_pred = classifier.predict(sc.transform(np.array([new_data])))\n",
    "test_pred = (test_pred>0.2)\n",
    "print(f'There is tend to death at the said condition {test_pred}')\n",
    "#There is tend to death at the said condition [[False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10703121]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of death at the said condition is: [[10.703121]]\n"
     ]
    }
   ],
   "source": [
    "#Analytical Questions\n",
    "#District(1),Imperial_Circle(2), Community(3), Month(5),Weekday(6),Hour(7), Light Condition(18) and Road Condition(19) and Severity\n",
    "#Q2. What is the probability of death on the dry road of district 3, imperial circle 2 of community 1 \n",
    "#on monday morning at 8am of January?\n",
    "\"\"\"Solution:\n",
    "    District - 3 ---\n",
    "    Imperial Circle - 3\n",
    "    Community - 5\n",
    "    Month - 1 -\n",
    "    Weekday - 2 - \n",
    "    Hour - 8\n",
    "    Light Condition - Morning - 1 - [1]\n",
    "    Road Condition - Dry - 0 - [0]\n",
    "    \"\"\"\n",
    "test_data = [3,3,5,1,2,8,1,0]\n",
    "test_pred = classifier.predict(scaler.transform([test_data]))\n",
    "#new_data = [1.0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "#test_pred = classifier.predict(sc.transform(np.array([new_data])))\n",
    "#test_pred = (new_pred>0.2)\n",
    "print(f'The probability of death at the said condition is: {test_pred*100}')\n",
    "#10.70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analytical Questions\n",
    "#District(1),Imperial_Circle(2), Community(3), Month(5),Weekday(6),Hour(7), Light Condition(18) and Road Condition(19) and Severity\n",
    "#Q3. What is the probability of death during daytime at 12:00 in community 2, imperial circle 4 of district 6 during June wednesday \n",
    "#when the road is wet?\n",
    "\"\"\"Solution:\n",
    "    District - 6 ---\n",
    "    Imperial Circle - 4\n",
    "    Community - 2\n",
    "    Month - 6 -\n",
    "    Weekday - 4 - \n",
    "    Hour - 12\n",
    "    Light Condition - Day - 0 - [0]\n",
    "    Road Condition - Wet - 1 - [1]\n",
    "    \"\"\"\n",
    "test_data = [6,4,2,6,4,12,0,1]\n",
    "test_pred = classifier.predict(scaler.transform([test_data]))\n",
    "#new_data = [1.0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "#test_pred = classifier.predict(sc.transform(np.array([new_data])))\n",
    "#test_pred = (new_pred>0.2)\n",
    "print(f'The probability of death at the said condition is: {test_pred*100}')\n",
    "#13.1%%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thus binary accident modeling can be done using Artificial Neural Networks. This model can be used to predict the probability of accident severity to occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network for Multiple Classification of Accident Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this model, we build an artificial neural network (ANN) for multi-class classification of accident data. We now implement previously built model into another data with some recommended change to make multi-class classification.  Change of data is not mandatory but to show the model can work on different data, we will use another data obtained from EUSKA."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Firstly, we begin with some adjustment with the data and understanding the relation between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import the dataset\n",
    "dataset = pd.read_csv('Bremen_modified.csv')\n",
    "#Fill the empty spaces and integer to represent 'NA'.\n",
    "#In this data it has some null values in 'Traffic_Light_System' column.\n",
    "#Hence we represent it with 2.\n",
    "#Traffic light system: 2--->NA, 1--->Working and 0--->Out of order\n",
    "dataset['Traffic_Light_System'].fillna(2, inplace = True)\n",
    "dataset.loc[dataset['Traffic_Light_System'] == 8] = 1\n",
    "dataset.loc[dataset['Traffic_Light_System'] == 9] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Tool for Correlation between variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before going for modeling, lets study the relationship between the variables involved through correlation diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = dataset[['month','lighting_conditions', 'road_conditions', 'location', 'street_class', 'day_of_week', 'hour_cat', 'season', 'Traffic_Light_System','accident_category']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 1, 4, 2, 6, 0], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['accident_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First lets import the library\n",
    "import seaborn as sns\n",
    "corr = corr_data.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The diagram shows that accident severity has negative relation with traffic light system, season, hour, weekday and positive relation with light and road conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Tools for Preprocessing of variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Select the variables for training and testing ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'lighting_conditions', 'road_conditions', 'location',\n",
       "       'street_class', 'accident_category', 'day_of_week', 'vacation',\n",
       "       'hour_cat', 'season', 'Traffic_Light_System'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take only those variables which can have effect to accident, \n",
    "#Month(3),Light Condition(9) and Road Condition(10), location(12), \n",
    "#street_class(13),Weekday(37), vacation(39), hour_cat(50), season(51), traffic_light_system(52)\n",
    "check = dataset.iloc[:, [3,9,10,12,13,14,37,39, 50, 51, 52]].columns \n",
    "X_ = dataset.iloc[:, [3,9,10,12,13,37,50,51,52]].values \n",
    "y_ = dataset.iloc[:, [14]].values\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "#Check the types of the variables\n",
    "print(X_.dtype)\n",
    "print(y_.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical values into integers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have to select only those independent variables that influence dependent variables and should check the types of these variables. String variables should be converted to floating values, if any. In our data there are no string values. Had there been string values, we would have converted the column using: \n",
    "\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [<Index of column>])], remainder='passthrough')\n",
    "X[:, <Index of column>:] = np.array(ct.fit_transform(X[:, <Index of column>:]), dtype=np.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill out the missing values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since the variables are found to be floats and integers, it is fine to proceed. Now check for null values and if any fill it with the column mean or median."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fill out the missing values with their mean\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, <range of columns to check for>] = imputer.transform(X[:, <range of columns to check for>])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dependent variable into categories "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check the categories of the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 21715, 3: 4831, 1: 6783, 4: 730, 2: 661, 6: 191, 0: 361})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "a = np.array(dataset)\n",
    "b = collections.Counter(dataset['accident_category'])\n",
    "b"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So there are seven categories in the dataset: \n",
    "0 = NA\n",
    "1 = accident with fatalities\n",
    "2 = accident with serious injuries\n",
    "3 = accident with minor injuries\n",
    "4 = serious accident withdamage\n",
    "5 = other property damage accident without exposure to alcohol\n",
    "6 = other property damage accident under the influence of alcohol"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we use LabelEncoder class to encode the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "#import sklearn.utils.validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = dataset.iloc[:, [14]].values\n",
    "y_ = y_.ravel()\n",
    "encoder = LabelEncoder()\n",
    "#encoder.fit(y)\n",
    "encoded_y = encoder.fit_transform(y_)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_ = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35272, 9)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Tools for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is necessary to split the data into two sections before proceeding for modeling. Also there is a question that whether data standardizations should be done before or after splitting. It should be kept in mind that if scaling is done before splitting then there will be leakage of information between training dataset and testing dataset which makes the model testing meaningless. Hence, there should be no doubt that data scaling should be done only after splitting the dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is normal practice to split the dataset in the ration of 80:20 between training set and testing set. random_state varible will split the data with same random effect, so if this variable is not set then there is no point of splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now is the time for standardizing the dataset. However, in data science practiotioners are often in confusion whether to standardize or normalize the data. It should be noted that data standardization works for all sorts of data and gives the range of values generally from -3 to +3 while data normalization is fine for only those data with normal distribution and it gives range betwen 0 and 1. So, as a rule of thumb we will do data standardization here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `StandardScaler` from `sklearn.preprocessing`\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the train set\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)\n",
    "#It should be kept in mind never to use fit() function for testing set. \n",
    "#If it is used, fit() method will create a new scaler for testing set also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28217, 9)\n",
      "(7055, 9)\n",
      "(28217, 7)\n",
      "(7055, 7)\n"
     ]
    }
   ],
   "source": [
    "#See the shape of training and testing set\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To build the model, we initilize it with Sequential constructor at first. The parameters for modeling should be chosen based on the input data and output data. Number of hidden layers are chosen either:\n",
    "    a. Between the number of input and output data\n",
    "    b. Hit and trial basis for which the model performs the best."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is the explanation of our chosen parameters:\n",
    "input_dim = 9: There are nine training variables in our data\n",
    "'activation' of hidden layers  = 'relu': To remove the linearity between variables.\n",
    "kernel_initializer = 'uniform' : To uniformly initilize the model\n",
    "units = 8 : Rule of thumb is (input variables + output variables)/2. Not mandatory though but in this case we followed this                 rule.\n",
    "'activation' of output layer = 'sigmoid': Our output is binary so we chose 'sigmoid'. Had it been multi-class, we would have                                             chose 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "classifier = Sequential()\n",
    "\n",
    "# Add an input+hidden layer \n",
    "classifier.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 9))\n",
    "\n",
    "# Add first hidden layer \n",
    "classifier.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# Add second hidden layer \n",
    "classifier.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# Add third hidden layer \n",
    "#classifier.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#model.add(Dropout(rate = 0.3))\n",
    "\n",
    "# Add an output layer \n",
    "classifier.add(Dense(7, kernel_initializer = 'uniform', activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Know the properties of model we are building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 63        \n",
      "=================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.03611917,  0.01009812, -0.04977904,  0.02509824, -0.0389112 ,\n",
       "          0.03268832, -0.00483315, -0.0135016 ],\n",
       "        [-0.01707311,  0.03573778,  0.02328708,  0.04940968,  0.01049651,\n",
       "          0.03830342,  0.00475037,  0.01743997],\n",
       "        [ 0.01816064,  0.03972795, -0.0421914 ,  0.03257842, -0.0324412 ,\n",
       "         -0.03615168,  0.01488013,  0.02419344],\n",
       "        [-0.01338985,  0.01110134,  0.04950127,  0.02190221,  0.0347605 ,\n",
       "          0.00556065, -0.03170203, -0.01818625],\n",
       "        [-0.03367292,  0.04531637, -0.04982729,  0.01281477, -0.00927939,\n",
       "          0.0477411 ,  0.04094234,  0.0462489 ],\n",
       "        [-0.01975135, -0.01608164,  0.01609418, -0.00566014,  0.01588279,\n",
       "         -0.01185561, -0.00143613,  0.04882767],\n",
       "        [-0.04247141, -0.04345937, -0.00649829,  0.04247237,  0.02131499,\n",
       "          0.01816144, -0.01973163,  0.02055135],\n",
       "        [-0.02223524, -0.00251583, -0.01792654,  0.0450976 ,  0.02255063,\n",
       "          0.00793964, -0.01843362, -0.00633808],\n",
       "        [-0.01027837,  0.01223097, -0.00904312, -0.03035114,  0.03470011,\n",
       "          0.04273174, -0.01630713, -0.03635033]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.01034839,  0.01958777,  0.00020424,  0.01590503, -0.02444935,\n",
       "         -0.00807264, -0.02242692, -0.03364766],\n",
       "        [ 0.01656114,  0.04311717,  0.00199388,  0.02469516,  0.04583062,\n",
       "          0.01848665, -0.02498519, -0.00348141],\n",
       "        [-0.01356027, -0.01747279,  0.0155785 , -0.00322523,  0.04649551,\n",
       "         -0.03169881, -0.04846491, -0.02314123],\n",
       "        [-0.04718485,  0.04494995,  0.00758287,  0.00171553,  0.00515334,\n",
       "          0.00194596,  0.03653443, -0.00117391],\n",
       "        [ 0.03510238,  0.04926323,  0.03981011, -0.00674213,  0.04391729,\n",
       "          0.01325777, -0.03476048,  0.04462688],\n",
       "        [-0.03147683, -0.04702077, -0.02950276,  0.02897212,  0.02539775,\n",
       "          0.01414632, -0.04149635, -0.03629265],\n",
       "        [-0.01045557,  0.03796467, -0.02872816,  0.03297279,  0.00920569,\n",
       "          0.00091555, -0.01978397,  0.02030536],\n",
       "        [ 0.0003469 ,  0.02817288,  0.00558575,  0.01351135, -0.03124975,\n",
       "         -0.01199729,  0.00937079,  0.0113428 ]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.0130265 , -0.00677267,  0.04827059,  0.03292442,  0.00160855,\n",
       "          0.04405624,  0.03966621, -0.02898512],\n",
       "        [-0.03016404,  0.0269399 , -0.01158811,  0.02139247, -0.01825299,\n",
       "         -0.01420586,  0.04118944,  0.00543072],\n",
       "        [ 0.03379274, -0.02188777, -0.02023956, -0.04825279, -0.04593548,\n",
       "         -0.04480133,  0.03063628,  0.00332823],\n",
       "        [ 0.00361856,  0.02491543,  0.0407218 ,  0.03964126,  0.0143888 ,\n",
       "         -0.01529455,  0.0227958 ,  0.02993269],\n",
       "        [ 0.01843521, -0.01516914,  0.00059013,  0.02522344,  0.03937757,\n",
       "          0.03302487, -0.00046781,  0.0381383 ],\n",
       "        [-0.01625932,  0.01230707,  0.0083956 ,  0.00428187,  0.00726507,\n",
       "         -0.01058996, -0.03399323,  0.04700006],\n",
       "        [ 0.03687118,  0.0340803 ,  0.02520627,  0.00300721,  0.03354493,\n",
       "         -0.01792637, -0.04123827, -0.04278949],\n",
       "        [-0.02672896,  0.0356832 ,  0.03495354,  0.02606345,  0.04633116,\n",
       "          0.02343703,  0.01791208,  0.02403703]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.01175074,  0.03869728,  0.0035928 , -0.01540982, -0.03220332,\n",
       "          0.03947871, -0.03977406],\n",
       "        [-0.04162768,  0.01440188, -0.04679617, -0.04328817, -0.01715151,\n",
       "         -0.03446207,  0.03281475],\n",
       "        [ 0.04698661, -0.0015238 , -0.0083104 ,  0.04263382, -0.02236274,\n",
       "         -0.02208896, -0.02387961],\n",
       "        [-0.019469  ,  0.03352224,  0.03930948, -0.03813427,  0.04812075,\n",
       "         -0.03756503,  0.02083408],\n",
       "        [ 0.02683451, -0.04631928,  0.03748253, -0.02403457,  0.00397905,\n",
       "         -0.00250645, -0.02610718],\n",
       "        [-0.00125331,  0.00264196, -0.0472545 , -0.04116243, -0.019022  ,\n",
       "         -0.00489945,  0.03413593],\n",
       "        [-0.00165461, -0.01702995,  0.00153843, -0.0349615 , -0.03422355,\n",
       "         -0.02331513, -0.04011091],\n",
       "        [ 0.03515616,  0.03670135,  0.02033336, -0.01984805,  0.04221049,\n",
       "          0.04096563, -0.04573157]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "classifier.output_shape\n",
    "\n",
    "# Model summary\n",
    "classifier.summary()\n",
    "\n",
    "# Model configuration\n",
    "classifier.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "classifier.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is an explanation of parameters chosen for compiling and fitting:\n",
    "loss = 'binary_crossentropy':The model is binary\n",
    "optimizer = 'adam': Stochastic gradient descent(SGD) is suitable approach to find the global minimum between over-fitting and under-fitting. 'adam' is a type of SGD\n",
    "metrics = 'accuracy': We want to quantify the performance and accuracy of model.\n",
    "epochs = 50: It is set on hit and trail basis. Can be changed according to the model performance.\n",
    "batch_size = 15: It is set on hit and trail basis. Can be changed according to the model performance.\n",
    "verbose = 1: To see the model progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28217/28217 [==============================] - 4s 150us/step - loss: 0.8424 - accuracy: 0.73070s - loss: 0.893\n",
      "Epoch 2/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5900 - accuracy: 0.8114\n",
      "Epoch 3/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5771 - accuracy: 0.8179\n",
      "Epoch 4/50\n",
      "28217/28217 [==============================] - 3s 98us/step - loss: 0.5746 - accuracy: 0.8179\n",
      "Epoch 5/50\n",
      "28217/28217 [==============================] - 3s 94us/step - loss: 0.5731 - accuracy: 0.8179\n",
      "Epoch 6/50\n",
      "28217/28217 [==============================] - 3s 97us/step - loss: 0.5727 - accuracy: 0.8179\n",
      "Epoch 7/50\n",
      "28217/28217 [==============================] - 3s 98us/step - loss: 0.5715 - accuracy: 0.8179\n",
      "Epoch 8/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5708 - accuracy: 0.8179\n",
      "Epoch 9/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5705 - accuracy: 0.8179\n",
      "Epoch 10/50\n",
      "28217/28217 [==============================] - 3s 101us/step - loss: 0.5700 - accuracy: 0.8179\n",
      "Epoch 11/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5702 - accuracy: 0.8179\n",
      "Epoch 12/50\n",
      "28217/28217 [==============================] - 3s 102us/step - loss: 0.5696 - accuracy: 0.8179\n",
      "Epoch 13/50\n",
      "28217/28217 [==============================] - 3s 98us/step - loss: 0.5697 - accuracy: 0.8179\n",
      "Epoch 14/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5696 - accuracy: 0.8179\n",
      "Epoch 15/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5691 - accuracy: 0.8179\n",
      "Epoch 16/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5689 - accuracy: 0.8179 0s - los\n",
      "Epoch 17/50\n",
      "28217/28217 [==============================] - 3s 101us/step - loss: 0.5681 - accuracy: 0.8180\n",
      "Epoch 18/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5687 - accuracy: 0.8179 0s - loss: 0.566\n",
      "Epoch 19/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5691 - accuracy: 0.8179 1s - loss: 0.5603  - ETA: 1s - ETA: 0s - loss:\n",
      "Epoch 20/50\n",
      "28217/28217 [==============================] - 3s 101us/step - loss: 0.5687 - accuracy: 0.8179\n",
      "Epoch 21/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5688 - accuracy: 0.8179\n",
      "Epoch 22/50\n",
      "28217/28217 [==============================] - 3s 97us/step - loss: 0.5684 - accuracy: 0.8179 0s - los\n",
      "Epoch 23/50\n",
      "28217/28217 [==============================] - 3s 98us/step - loss: 0.5686 - accuracy: 0.8179\n",
      "Epoch 24/50\n",
      "28217/28217 [==============================] - 3s 104us/step - loss: 0.5687 - accuracy: 0.8179\n",
      "Epoch 25/50\n",
      "28217/28217 [==============================] - 3s 124us/step - loss: 0.5682 - accuracy: 0.8179\n",
      "Epoch 26/50\n",
      "28217/28217 [==============================] - 4s 134us/step - loss: 0.5686 - accuracy: 0.8179\n",
      "Epoch 27/50\n",
      "28217/28217 [==============================] - 4s 131us/step - loss: 0.5682 - accuracy: 0.8180\n",
      "Epoch 28/50\n",
      "28217/28217 [==============================] - 3s 107us/step - loss: 0.5688 - accuracy: 0.8179\n",
      "Epoch 29/50\n",
      "28217/28217 [==============================] - 3s 113us/step - loss: 0.5681 - accuracy: 0.8179\n",
      "Epoch 30/50\n",
      "28217/28217 [==============================] - 3s 107us/step - loss: 0.5679 - accuracy: 0.8179\n",
      "Epoch 31/50\n",
      "28217/28217 [==============================] - 3s 104us/step - loss: 0.5685 - accuracy: 0.8179\n",
      "Epoch 32/50\n",
      "28217/28217 [==============================] - 3s 105us/step - loss: 0.5682 - accuracy: 0.8179\n",
      "Epoch 33/50\n",
      "28217/28217 [==============================] - 3s 113us/step - loss: 0.5681 - accuracy: 0.8179\n",
      "Epoch 34/50\n",
      "28217/28217 [==============================] - 3s 105us/step - loss: 0.5676 - accuracy: 0.8179\n",
      "Epoch 35/50\n",
      "28217/28217 [==============================] - 3s 123us/step - loss: 0.5679 - accuracy: 0.8179\n",
      "Epoch 36/50\n",
      "28217/28217 [==============================] - 3s 105us/step - loss: 0.5677 - accuracy: 0.8179\n",
      "Epoch 37/50\n",
      "28217/28217 [==============================] - 3s 110us/step - loss: 0.5678 - accuracy: 0.8179\n",
      "Epoch 38/50\n",
      "28217/28217 [==============================] - 3s 92us/step - loss: 0.5677 - accuracy: 0.8179\n",
      "Epoch 39/50\n",
      "28217/28217 [==============================] - 3s 110us/step - loss: 0.5676 - accuracy: 0.8179\n",
      "Epoch 40/50\n",
      "28217/28217 [==============================] - 3s 114us/step - loss: 0.5678 - accuracy: 0.8179\n",
      "Epoch 41/50\n",
      "28217/28217 [==============================] - 3s 123us/step - loss: 0.5675 - accuracy: 0.8179\n",
      "Epoch 42/50\n",
      "28217/28217 [==============================] - 3s 97us/step - loss: 0.5673 - accuracy: 0.8179 0s - loss: 0.5677  - ETA: 0s - loss: 0.5677 - accuracy: \n",
      "Epoch 43/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5670 - accuracy: 0.8179 2s - loss: - - ETA: 0s - loss: 0.5648 - accu\n",
      "Epoch 44/50\n",
      "28217/28217 [==============================] - 3s 100us/step - loss: 0.5674 - accuracy: 0.81790s - loss: 0.5660 - ac\n",
      "Epoch 45/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5674 - accuracy: 0.8179\n",
      "Epoch 46/50\n",
      "28217/28217 [==============================] - 3s 96us/step - loss: 0.5673 - accuracy: 0.8178\n",
      "Epoch 47/50\n",
      "28217/28217 [==============================] - 3s 93us/step - loss: 0.5669 - accuracy: 0.8179\n",
      "Epoch 48/50\n",
      "28217/28217 [==============================] - 3s 95us/step - loss: 0.5667 - accuracy: 0.8179\n",
      "Epoch 49/50\n",
      "28217/28217 [==============================] - 3s 97us/step - loss: 0.5669 - accuracy: 0.8179\n",
      "Epoch 50/50\n",
      "28217/28217 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.81 - 3s 93us/step - loss: 0.5671 - accuracy: 0.8179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f8a6278d48>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "classifier.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.1344088e-18, 9.2208444e-04, 2.1833414e-02, 1.3183416e-01,\n",
       "         2.4224961e-02, 6.4282197e-01, 7.5532724e-03],\n",
       "        [2.0640197e-22, 1.9982322e-04, 1.4586992e-02, 9.6023127e-02,\n",
       "         1.5475470e-02, 6.1235613e-01, 4.1390439e-03],\n",
       "        [6.0820946e-19, 1.1828132e-03, 2.7333288e-02, 1.7848596e-01,\n",
       "         2.4803627e-02, 7.5790352e-01, 7.1906522e-03],\n",
       "        [1.8593946e-22, 7.0612255e-04, 2.7530745e-02, 2.1271019e-01,\n",
       "         1.9018115e-02, 8.5481405e-01, 4.3741078e-03],\n",
       "        [3.1460813e-20, 6.7369308e-04, 2.0896798e-02, 1.3846067e-01,\n",
       "         1.9724393e-02, 7.0758462e-01, 5.1402720e-03],\n",
       "        [1.1471232e-06, 7.2337836e-01, 3.7733017e-07, 5.7950349e-08,\n",
       "         2.5370340e-05, 3.1466590e-07, 6.7011652e-10],\n",
       "        [2.5843134e-21, 1.0118494e-03, 3.1694029e-02, 2.3375633e-01,\n",
       "         2.2330116e-02, 8.5872722e-01, 5.6223287e-03],\n",
       "        [5.5933805e-16, 7.3850912e-04, 2.3113510e-02, 1.3798927e-01,\n",
       "         2.6981933e-02, 6.1030728e-01, 1.1960580e-02],\n",
       "        [7.3501929e-18, 7.4501941e-04, 2.4644496e-02, 1.5913746e-01,\n",
       "         2.4169140e-02, 7.0188570e-01, 8.7869093e-03],\n",
       "        [2.4060738e-19, 4.6671505e-04, 2.5491113e-02, 1.8781042e-01,\n",
       "         2.1149818e-02, 7.8204590e-01, 7.7329837e-03]], dtype=float32),\n",
       " array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred = y_pred>0.2\n",
    "y_pred[:10],y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7055/7055 [==============================] - 0s 41us/step\n",
      "[0.5707580119265807, 0.8160170316696167]\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(X_test, y_test,verbose=1)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The confusion matrix is a table which depicts correct and incorrect predictions. It will include the false positives and false negative classification as well. The diagonal values are correct ones while the rest are incorrect ones.\n",
    "- Precision measures the 'exactness' of the model. Higher precision value means higher accuracy of the model.\n",
    "- Recall  measures the 'completeness' of the model. Higher recall value means higher coverage of the model.\n",
    "- The F1 Score also called as F-score gives the 'weighted average of precision and recall'. Higher F1 score means higher accuracy and coverage.\n",
    "- The Kappa also called as Cohen’s kappa gives the accuracy of classification normalized by the 'imbalance of the classes in the data'.\n",
    "\n",
    "In the section below, we compute each one of these to quantify the strength of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  61    0    0    0    0    0    0]\n",
      " [   0 1311    0    0    0    4    0]\n",
      " [   0    0    0    0    0  127    0]\n",
      " [   0    0    0    0    0  987    0]\n",
      " [   0    0    0    0    0  142    0]\n",
      " [   0    0    0    0    0 4385    0]\n",
      " [   0    0    0    0    0   38    0]]\n"
     ]
    }
   ],
   "source": [
    "# Import the modules from `sklearn.metrics`\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = np.argmax(y_pred, axis=1) \n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.82\n",
      "\n",
      "Micro Precision: 0.82\n",
      "Micro Recall: 0.82\n",
      "Micro F1-score: 0.82\n",
      "\n",
      "Macro Precision: 0.97\n",
      "Macro Recall: 0.43\n",
      "Macro F1-score: 0.41\n",
      "\n",
      "Weighted Precision: 0.67\n",
      "Weighted Recall: 0.82\n",
      "Weighted F1-score: 0.74\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       1.00      1.00      1.00        61\n",
      "     Class 2       1.00      1.00      1.00      1315\n",
      "     Class 3       1.00      0.00      0.00       127\n",
      "     Class 4       1.00      0.00      0.00       987\n",
      "     Class 5       1.00      0.00      0.00       142\n",
      "     Class 6       0.77      1.00      0.87      4385\n",
      "     Class 7       1.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.82      7055\n",
      "   macro avg       0.97      0.43      0.41      7055\n",
      "weighted avg       0.86      0.82      0.74      7055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro', zero_division = True)))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro', zero_division = True)))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='macro', zero_division = True)))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6', 'Class 7'], zero_division = True))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thus the model can be quantified statistically in order to find out its strength/performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In conclusion, we can use neural network techniques to understand the pattern of accident data. It can also depict the relation between the variable of the data. The model can be used to predict both binary and multi-class outputs hoping it would be one of the effect tools for studying the traffic safety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
